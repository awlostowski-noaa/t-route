{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import subprocess\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ruamel.yaml\n",
    "\n",
    "# define script parameters\n",
    "threshold = [0, 100, 250, 500, 750, 1000]\n",
    "method = [\"merge\", \"prune_merge\", \"prune_snap_merge\"]\n",
    "dt = [300,100,10]\n",
    "tw = 933020089\n",
    "nts = 8640\n",
    "\n",
    "# define filepaths\n",
    "root = pathlib.Path(\"..\").resolve()\n",
    "output_dir = os.path.join(root, \"test\", \"output\", \"text\")\n",
    "routelink_path = os.path.join(root,\"test\",\"input\",\"geo\",\"Channels\")\n",
    "yaml_dir = os.path.join(root,\"test\",\"input\",\"yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct augmented networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in method:\n",
    "    \n",
    "    for t in threshold:\n",
    "        \n",
    "        if t!= 0:\n",
    "        \n",
    "            if m == \"merge\":\n",
    "                cmd_strs = [\n",
    "                    \"python\", \n",
    "                    \"nhd_network_augment.py\",\n",
    "                    \"-t\",\n",
    "                    str(t), \n",
    "                    \"--network\",\n",
    "                    \"Florence_FULL_RES\"]\n",
    "\n",
    "            if m == \"prune_merge\":\n",
    "                cmd_strs = [\n",
    "                    \"python\", \n",
    "                    \"nhd_network_augment.py\",\n",
    "                    \"-t\",\n",
    "                    str(t), \n",
    "                    \"--network\",\n",
    "                    \"Florence_FULL_RES\",\n",
    "                    \"-p\"]\n",
    "\n",
    "            if m == \"prune_snap_merge\":\n",
    "                cmd_strs = [\n",
    "                    \"python\", \n",
    "                    \"nhd_network_augment.py\",\n",
    "                    \"-t\",\n",
    "                    str(t), \n",
    "                    \"--network\",\n",
    "                    \"Florence_FULL_RES\",\n",
    "                    \"-p\",\n",
    "                    \"-s\"] \n",
    "\n",
    "            subprocess.run(\n",
    "                cmd_strs,\n",
    "                cwd=os.path.join(root,\"src\",\"python_framework_v02\",\"troute\")\n",
    "            )\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Muskingum-Cunge routing model on augmented networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_violation = []\n",
    "pct_violation = []\n",
    "av_violation = []\n",
    "pct_violation = []\n",
    "method_list = []\n",
    "threshold_list = []\n",
    "outlet_flow = []\n",
    "for m in method:\n",
    "    \n",
    "    for t in threshold:\n",
    "        \n",
    "        method_list.extend([m])\n",
    "        threshold_list.extend([t])\n",
    "\n",
    "        dir_name  = \"RouteLink_Florence_FULL_RES_\"+str(t)+\"m_\"+m  \n",
    "        routelink_name = dir_name+\".pkl\"\n",
    "        crosswalk_name = \"CrossWalk_Florence_FULL_RES_\"+str(t)+\"m_\"+m+\".json\"\n",
    "        \n",
    "        if t != 0:\n",
    "            # edit yaml file - Florence_Benchmark-augment.yaml\n",
    "            yaml = ruamel.yaml.YAML()\n",
    "            with open(os.path.join(yaml_dir,'Florence_Benchmark.yaml')) as fp:\n",
    "                data = yaml.load(fp)\n",
    "\n",
    "            data['supernetwork_parameters']['title_string'] = \"Florence_TEST_\" + str(t) + \"m_\" + m\n",
    "            data['supernetwork_parameters']['run_augmented_network'] = True        \n",
    "            data['supernetwork_parameters']['augment_routelink'] = os.path.join(routelink_path,dir_name,routelink_name)\n",
    "            data['supernetwork_parameters']['cross_walk'] = os.path.join(routelink_path,dir_name,crosswalk_name)\n",
    "\n",
    "            new_yaml_name = \"Florence_Benchmark_\" + str(t) +\"m_\" + m + \".yaml\"\n",
    "            with open(os.path.join(yaml_dir,new_yaml_name), \"w\") as f:\n",
    "                yaml.dump(data, f)\n",
    "        else:\n",
    "            new_yaml_name = \"Florence_Benchmark.yaml\"\n",
    "\n",
    "        # execute the model\n",
    "        print(\"Running t-route with threshold length of\", t, \"and method:\", m, \"...\")\n",
    "        \n",
    "        subprocess.run(\n",
    "        [\n",
    "            \"python\", \n",
    "            \"compute_nhd_routing_SingleSeg_v02.py\",\n",
    "            \"-f\",\n",
    "            \"../../test/input/yaml/\" + new_yaml_name, \n",
    "            \"-v\"],\n",
    "        cwd=os.path.join(root,\"src\",\"python_routing_v02\"),\n",
    "        )\n",
    "        \n",
    "        # get Courant data\n",
    "        if t == 0:\n",
    "            dat_c = pd.read_csv(os.path.join(output_dir, \"courant_Florence_TEST.csv\"), index_col=[1]) \n",
    "        else:\n",
    "            filename = \"courant_Florence_TEST_\" + str(t) + \"m_\" + m + \".csv\" \n",
    "            dat_c = pd.read_csv(os.path.join(output_dir, filename), index_col=[1]) \n",
    "            \n",
    "        n_violation.extend([dat_c.loc[\"n_violation\"].value])\n",
    "        av_violation.extend([dat_c.loc[\"av_violation\"].value])\n",
    "        pct_violation.extend([dat_c.loc[\"pct_violation\"].value])\n",
    "        \n",
    "        # extract flow at outlet node\n",
    "        if t == 0:\n",
    "            dat_f = pd.read_csv(os.path.join(output_dir, \"flowveldepth_Florence_TEST.csv\"), index_col=[0])  \n",
    "        else:\n",
    "            filename = \"flowveldepth_Florence_TEST_\" + str(t) + \"m_\" + m + \".csv\"\n",
    "            dat_f = pd.read_csv(os.path.join(output_dir, filename), index_col=[0]) \n",
    "\n",
    "        outlet_flow.append(dat_f.loc[tw].values)\n",
    "        \n",
    "simtime = dat_f.columns.values.astype('float32')\n",
    "\n",
    "# Package courant results in a dataframe\n",
    "courant_augment_sensitivity = pd.DataFrame(\n",
    "    {'threshold_length': threshold_list,\n",
    "     'method': method_list,\n",
    "     'n_violation': n_violation,\n",
    "     'av_violation': av_violation,\n",
    "     'pct_violation': pct_violation}\n",
    ")\n",
    "\n",
    "# package Flow results in dataframe\n",
    "B = np.concatenate([np.array(x)[None,:] for x in outlet_flow], axis=0)\n",
    "flow_augment_sensitivity = pd.DataFrame(data = B)\n",
    "flow_augment_sensitivity.columns = simtime\n",
    "flow_augment_sensitivity.insert(loc=0, column='threshold_length', value=courant_augment_sensitivity[\"threshold_length\"])\n",
    "flow_augment_sensitivity.insert(loc=1, column='method', value=courant_augment_sensitivity[\"method\"])\n",
    "flow_augment_sensitivity = flow_augment_sensitivity.melt(id_vars = ['threshold_length','method'], value_vars = simtime, var_name = \"Simulation Time (dys)\", value_name = \"Flow (cms)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Muskingum-Cunge model over a range of timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_violation = []\n",
    "pct_violation = []\n",
    "av_violation = []\n",
    "outlet_flow = []\n",
    "simtime = []\n",
    "for t in dt:\n",
    "    \n",
    "    # edit yaml file - Florence_Benchmark-augment.yaml\n",
    "    yaml = ruamel.yaml.YAML()\n",
    "    with open(os.path.join(yaml_dir,'Florence_Benchmark.yaml')) as fp:\n",
    "        data = yaml.load(fp)\n",
    "\n",
    "    data['run_parameters']['dt'] = t\n",
    "    data['run_parameters']['qts_subdivisions'] = int(3600/t)\n",
    "    data['run_parameters']['nts'] = int((30*86400)/t)\n",
    "    data['supernetwork_parameters']['title_string'] = \"Florence_TEST_\" + str(t) + \"secs\"      \n",
    "\n",
    "    new_yaml_name = \"Florence_Benchmark_\" + str(t) + \"secs\" \".yaml\"\n",
    "    with open(os.path.join(yaml_dir,new_yaml_name), \"w\") as f:\n",
    "        yaml.dump(data, f)\n",
    "        \n",
    "    # execute the model\n",
    "    print(\"Running t-route with a\", t, \"second timestep\")\n",
    "\n",
    "    subprocess.run(\n",
    "    [\n",
    "        \"python\", \n",
    "        \"compute_nhd_routing_SingleSeg_v02.py\",\n",
    "        \"-f\",\n",
    "        \"../../test/input/yaml/\" + new_yaml_name, \n",
    "        \"-v\"],\n",
    "    cwd=os.path.join(root,\"src\",\"python_routing_v02\"),\n",
    "    )\n",
    "    \n",
    "    # extract courant metrics\n",
    "    filename = \"courant_Florence_TEST_\" + str(t) + \"secs.csv\"\n",
    "    dat_c = pd.read_csv(os.path.join(output_dir, filename), index_col=[1]) \n",
    "    n_violation.extend([dat_c.loc[\"n_violation\"].value])\n",
    "    av_violation.extend([dat_c.loc[\"av_violation\"].value])\n",
    "    pct_violation.extend([dat_c.loc[\"pct_violation\"].value])\n",
    "    \n",
    "    # extract flow timeseries\n",
    "    filename = \"flowveldepth_Florence_TEST_\" + str(t) + \"secs.csv\"\n",
    "    dat_f = pd.read_csv(os.path.join(output_dir, filename), index_col=[0]) \n",
    "    outlet_flow.append(dat_f.loc[tw].values)\n",
    "    simtime.append(dat_f.columns.values.astype('float32'))\n",
    "    \n",
    "# place Courant data in DataFrame\n",
    "courant_dt_sensitivity = pd.DataFrame(\n",
    "    {'dt (secs)': dt,\n",
    "     'n_violation': n_violation,\n",
    "     'av_violation': av_violation,\n",
    "     'pct_violation': pct_violation}\n",
    ")\n",
    "courant_dt_sensitivity = courant_dt_sensitivity.set_index('dt (secs)')\n",
    "\n",
    "# Join flow data into dataframe\n",
    "i = dt.index(300)\n",
    "outlet_flow_join = []\n",
    "outlet_flow_join.append(outlet_flow[i])\n",
    "for j, t in enumerate(dt, start = 0):\n",
    "    if t != 300:\n",
    "        x, i_x, i_y = np.intersect1d(simtime[i],simtime[j],return_indices=True)\n",
    "        outlet_flow_join.append(outlet_flow[j][i_y])\n",
    "        \n",
    "B = np.concatenate([np.array(x)[None,:] for x in outlet_flow_join], axis=0)\n",
    "flow_dt_sensitivity = pd.DataFrame(data = B)\n",
    "flow_dt_sensitivity.columns = simtime[i]\n",
    "flow_dt_sensitivity.insert(loc=0, column='dt (secs)', value=dt)\n",
    "flow_dt_sensitivity = flow_dt_sensitivity.melt(id_vars = ['dt (secs)'], value_vars =  simtime[i], var_name = \"Simulation Time (dys)\", value_name = \"Flow (cms)\")\n",
    "flow_dt_sensitivity = flow_dt_sensitivity.set_index('dt (secs)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot sensitivity of flow to timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = (flow_dt_sensitivity.\n",
    "             reset_index().\n",
    "             pivot(index = \"Simulation Time (dys)\", columns = \"dt (secs)\", values = \"Flow (cms)\").\n",
    "             rename(columns = {10:\"dt = 10 secs\",\n",
    "                               100:\"dt = 100 secs\",\n",
    "                               300: \"dt = 300 secs\"})\n",
    "            )\n",
    "\n",
    "ax = df_plot.plot(\n",
    "    xlim = [15,20],\n",
    "    figsize = (9,5)\n",
    ")\n",
    "ax.set_ylabel(\"Flow (cms)\")\n",
    "ax.set_xlabel(\"Timestep\")\n",
    "ax.set_title(\"Timestep sensitivity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which augmentation method best reproduces the 10-second (near-stable) hydrograph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which augmented simulation best aligns with the short timestep simulaton?\n",
    "flow_10 = (flow_dt_sensitivity.\n",
    "                 reset_index().\n",
    "                 rename(columns = {\"dt (secs)\":\"dt\"}).\n",
    "                 query('dt == 10').\n",
    "                 set_index(\"Simulation Time (dys)\"))[[\"Flow (cms)\"]]\n",
    "\n",
    "RMSE = []\n",
    "for m in method:\n",
    "    \n",
    "    for t in threshold:\n",
    "        \n",
    "        flow_augmented = (flow_augment_sensitivity.\n",
    "                 query('method == @m and threshold_length == @t').\n",
    "                 set_index(\"Simulation Time (dys)\"))[[\"Flow (cms)\"]]\n",
    "        \n",
    "        flow_join = flow_augmented.join(flow_10, on = \"Simulation Time (dys)\", how = \"left\", lsuffix='_left', rsuffix='_right')\n",
    "        \n",
    "        flow_join[\"Sq. Error\"] = np.square(np.absolute(flow_join[\"Flow (cms)_left\"] - flow_join[\"Flow (cms)_right\"]))\n",
    "        RMSE.extend([np.sqrt(flow_join[\"Sq. Error\"].mean())])\n",
    "        \n",
    "\n",
    "compare_result = pd.DataFrame(\n",
    "    {'threshold_length': threshold_list,\n",
    "     'method': method_list,\n",
    "     'RMSE': RMSE}\n",
    ")\n",
    "\n",
    "print(compare_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = \"prune_snap_merge\"\n",
    "t = 750\n",
    "\n",
    "flow_plot = (flow_dt_sensitivity.\n",
    "                 reset_index().\n",
    "                 rename(columns = {\"dt (secs)\":\"dt\"}).\n",
    "                 query('dt == 10 or dt == 300').\n",
    "                 pivot(index = \"Simulation Time (dys)\", columns = \"dt\", values = \"Flow (cms)\").\n",
    "                 rename(columns = {10:\"dt = 10 secs\", 300:\"dt = 300 secs\"}).\n",
    "                 join(flow_augment_sensitivity.query('method == @m and threshold_length == @t').set_index(\"Simulation Time (dys)\").rename(columns = {\"Flow (cms)\":\"Augmented Network\"})[[\"Augmented Network\"]],\n",
    "                       on = \"Simulation Time (dys)\", \n",
    "                       how = \"left\", lsuffix='_left', \n",
    "                       rsuffix='_right')\n",
    "            )\n",
    "\n",
    "ax = flow_plot.plot(\n",
    "    xlim = [15,20],\n",
    "    figsize = (9,5)\n",
    ")\n",
    "ax.set_ylabel(\"Flow (cms)\")\n",
    "ax.set_xlabel(\"Simulation Time (days)\")\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save sensitivity results as .pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = os.path.join(root, \"test\", \"output\")\n",
    "\n",
    "(flow_dt_sensitivity.\n",
    " to_pickle(os.path.join(pkl_dir,\"flow_dt_sensitivity.pkl\"))\n",
    ")\n",
    "\n",
    "(courant_dt_sensitivity.\n",
    " to_pickle(os.path.join(pkl_dir,\"courant_dt_sensitivity.pkl\"))\n",
    ")\n",
    "\n",
    "(courant_augment_sensitivity.\n",
    " set_index([\"threshold_length\",\"method\"]).\n",
    " to_pickle(os.path.join(pkl_dir,\"courant_augment_sensitivity.pkl\"))\n",
    ")\n",
    "\n",
    "(flow_augment_sensitivity.\n",
    " set_index([\"threshold_length\",\"method\"]).\n",
    " to_pickle(os.path.join(pkl_dir,\"flow_augment_sensitivity.pkl\"))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
