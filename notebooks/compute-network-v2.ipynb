{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from itertools import chain, islice\n",
    "from functools import partial\n",
    "from joblib import delayed, Parallel\n",
    "import random\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "root = os.path.dirname(os.path.abspath(\"\"))\n",
    "\n",
    "fortran_source_dir = os.path.join(root, \"src\", \"fortran_routing\", \"mc_pylink_v00\", \"MC_singleSeg_singleTS\")\n",
    "sys.path.append(fortran_source_dir)\n",
    "sys.path.append(os.path.join(root, \"src\", \"python_framework_v02\"))\n",
    "sys.path.append(os.path.join(root, \"src\", \"python_routing_v02\"))\n",
    "\n",
    "## network/reach utilities & routing module\n",
    "import nhd_network_utilities_v02 as nnu\n",
    "import nhd_io\n",
    "import nhd_network\n",
    "import mc_reach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River network wave routing with t-route\n",
    "This notebook illustrates how the t-route code base routes flood waves through large river networks. We created an experiment where a  pulse of lateral inflows is uniformly applied to and routed through the CONUS mainstem supernetwork. Experiment results are visulalized for Mississippi River Basin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_qlats(data, nsteps, qlat):\n",
    "    \n",
    "    q1 = np.full((len(data.index), nsteps//10), 0, dtype='float32')\n",
    "    q2 = np.full((len(data.index), nsteps//10), qlat, dtype='float32')\n",
    "    q3 = np.full((len(data.index), nsteps//10), qlat, dtype='float32')\n",
    "    q4 = np.full((len(data.index), nsteps//10), 0, dtype='float32')\n",
    "    q5 = np.full((len(data.index), nsteps//10), 0, dtype='float32')\n",
    "    q6 = np.full((len(data.index), nsteps//10), 0, dtype='float32')\n",
    "    q7 = np.full((len(data.index), nsteps//10), 0, dtype='float32')\n",
    "    q8 = np.full((len(data.index), nsteps//10), 0, dtype='float32')\n",
    "    q9 = np.full((len(data.index), nsteps//10), 0, dtype='float32')\n",
    "    q10 = np.full((len(data.index), nsteps//10), 0, dtype='float32')\n",
    "    \n",
    "    q= np.concatenate((q1,q2,q3,q4,q5,q6,q7,q8,q9,q10),axis=1)\n",
    "    \n",
    "    ql = pd.DataFrame(q, index=data.index, columns=range(nsteps))\n",
    "    \n",
    "    return ql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying supernetwork connections set\n",
      "supernetwork connections set created.\n",
      "Organizing segments into reaches.\n",
      "Reach creation complete.\n",
      "Running network routing computations\n",
      "Now working on: 20331522 ...Now working on: 209929 ...Now working on: 10850322 ...Now working on: 21412883 ...Now working on: 23864346 ...Now working on: 2297884 ...Now working on: 8272933 ...Now working on: 18257965 ...Now working on: 3712048 ...Now working on: 18524217 ...Now working on: 12169285 ...Now working on: 3766342 ...Now working on: 23940171 ...Now working on: 17562700 ...Now working on: 12135518 ...Now working on: 24903800 ...Now working on: 6170754 ...Now working on: 20105349 ...Now working on: 20849803 ...Now working on: 21906573 ...Now working on: 15634575 ...Now working on: 9619605 ...Now working on: 3468447 ...Now working on: 3172512 ...Now working on: 23875749 ...Now working on: 11947179 ...Now working on: 10367150 ...Now working on: 16875696 ...Now working on: 15588530 ...Now working on: 13203635 ...Now working on: 10367158 ...Now working on: 8404151 ...Now working on: 1636535 ...Now working on: 6848697 ...Now working on: 17692863 ...Now working on: 2804929 ...Now working on: 8479948 ...Now working on: 2702541 ...Now working on: 18516172 ...Now working on: 939010255 ...Now working on: 1588433 ...Now working on: 8200407 ...Now working on: 20296925 ...Now working on: 17693919 ...Now working on: 4539621 ...Now working on: 5867753 ...Now working on: 10452202 ...Now working on: 12018926 ...Now working on: 10736883 ...Now working on: 23864566 ...Now working on: 25371895 ...Now working on: 23949563 ...Now working on: 54524 ...Now working on: 2788603 ...Now working on: 6724863 ...Now working on: 25020678 ...Now working on: 5290259 ...Now working on: 15568147 ...Now working on: 11690260 ...Now working on: 16918808 ...Now working on: 1523997 ...Now working on: 6141214 ...Now working on: 16884000 ...Now working on: 16910627 ...Now working on: 15506742 ...Now working on: 167578935 ...Now working on: 15604022 ...Now working on: 8835386 ...Now working on: 1609020 ...Now working on: 11160893 ...Now working on: 6318401 ...Now working on: 1657155 ...Now working on: 5298501 ...Now working on: 8992070 ...Now working on: 6134087 ...Now working on: 15604038 ...Now working on: 5205320 ...Now working on: 23832907 ...Now working on: 16933198 ...Now working on: 9660756 ...Now working on: 23871829 ...Now working on: 1643861 ...Now working on: 13176159 ...Now working on: 23881060 ...Now working on: 25055589 ...Now working on: 2805097 ...Now working on: 20372843 ...Now working on: 10452332 ...Now working on: 4438382 ...Now working on: 7843189 ...Now working on: 904010102 ...Now working on: 6264182 ...Now working on: 16944504 ...Now working on: 1670527 ...Now working on: 16659839 ...Now working on: 15576459 ...Now working on: 898449 ...Now working on: 5846422 ...Now working on: 23886240 ...Now working on: 9074086 ...Now working on: 25388456 ...Now working on: 5849520 ...Now working on: 3160499 ...Now working on: 1737140 ...Now working on: 20371899 ...Now working on: 7088581 ...Now working on: 10320326 ...Now working on: 17150414 ...Now working on: 1010002391 ...Now working on: 15714785 ...Now working on: 12954082 ...Now working on: 800227 ...Now working on: 16817635 ...Now working on: 7913958 ...Now working on: 15888878 ...Now working on: 1559026 ...Now working on: 9356790 ...Now working on: 2245123 ...Now working on: 23876101 ...Now working on: 7703046 ...Now working on: 18077192 ...Now working on: 12206602 ...Now working on: 17587726 ...Now working on: 7077392 ...Now working on: 23889434 ...Now working on: 18077224 ...Now working on: 626220 ...Now working on: 12175926 ...Now working on: 1970745 ...Now working on: 13229626 ...Now working on: 9316927 ...Now working on: 15048261 ...Now working on: 166195783 ...Now working on: 800351 ...Now working on: 6790753 ...Now working on: 10055266 ...Now working on: 17684066 ...Now working on: 25293410 ...Now working on: 28123750 ...Now working on: 8412775 ...Now working on: 9848429 ...Now working on: 11939441 ...Now working on: 8994418 ...Now working on: 8317553 ...Now working on: 22561410 ...Now working on: 22549123 ...Now working on: 12162694 ...Now working on: 6130319 ...Now working on: 14353046 ...Now working on: 1985180 ...Now working on: 10975909 ...Now working on: 13057708 ...Now working on: 23241390 ...Now working on: 7718580 ...Now working on: 10234553 ...Now working on: 10390202 ...Now working on: 5868233 ...Now working on: 2236109 ...Now working on: 15581903 ...Now working on: 17665749 ...Now working on: 8315605 ...Now working on: 12005077 ...Now working on: 1199836 ...Now working on: 1440477 ...Now working on: 26815201 ...Now working on: 16841444 ...Now working on: 9005799 ...Now working on: 23838450 ...Now working on: 15623927 ...Now working on: 22226684 ...Now working on: 8377087 ...Now working on: 15537927 ...Now working on: 21972746 ...Now working on: 25110300 ...Now working on: 6399779 ...Now working on: 6742822 ...Now working on: 2287399 ...Now working on: 12121910 ...Now working on: 2172729 ...Now working on: 163864378 ...Now working on: 17599293 ...Now working on: 4608830 ...Now working on: 12945216 ...Now working on: 17573699 ...Now working on: 12257100 ...Now working on: 1433451 ...Now working on: 28033899 ...Now working on: 6251384 ...Now working on: 23914361 ...Now working on: 9350011 ...Now working on: 13069184 ...Now working on: 9182098 ...Now working on: 6232986 ...Now working on: 18122652 ...Now working on: 4726685 ...Now working on: 18122654 ...Now working on: 9350061 ...Now working on: 15183793 ...Now working on: 28125112 ...Now working on: 17623995 ...Now working on: 8188863 ...Now working on: 11962312 ...Now working on: 947120082 ...Now working on: 1563610 ...Now working on: 22811611 ..."
     ]
    }
   ],
   "source": [
    "# specify the number of timesteps and the size of each timestep\n",
    "nts = 8000\n",
    "dt = 1800\n",
    "\n",
    "# ------- STEP 1 ---------\n",
    "\n",
    "print(\"Identifying supernetwork connections set\")\n",
    "\n",
    "test_folder = os.path.join(root, r\"test\")\n",
    "geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "supernetwork = 'Mainstems_CONUS'\n",
    "\n",
    "network_data = nnu.set_supernetwork_data(\n",
    "    supernetwork=supernetwork, geo_input_folder=geo_input_folder\n",
    ")\n",
    "\n",
    "# select only the necessary columns of geospatial data, set the DataFrame index\n",
    "cols = [v for c, v in network_data.items() if c.endswith(\"_col\")]\n",
    "data = nhd_io.read(network_data[\"geo_file_path\"])\n",
    "data = data[cols]\n",
    "data = data.set_index(network_data[\"key_col\"])\n",
    "\n",
    "# mask NHDNetwork to isolate test network of choice\n",
    "if \"mask_file_path\" in network_data:\n",
    "    data_mask = nhd_io.read_mask(\n",
    "        network_data[\"mask_file_path\"],\n",
    "        layer_string=network_data[\"mask_layer_string\"],\n",
    "    )\n",
    "    data = data.filter(data_mask.iloc[:, network_data[\"mask_key\"]], axis=0)\n",
    "\n",
    "# sort index\n",
    "data = data.sort_index()\n",
    "\n",
    "# replace downstreams\n",
    "data = nhd_io.replace_downstreams(data, network_data['downstream_col'], 0)\n",
    "\n",
    "# generate a lateral inflow time series\n",
    "qlats = step_qlats(data, nts, 10.0)\n",
    "\n",
    "# extract downstream connections for each node\n",
    "connections = nhd_network.extract_connections(data, network_data[\"downstream_col\"])\n",
    "\n",
    "print(\"supernetwork connections set created.\")\n",
    "\n",
    "# ------- STEP 2 ---------\n",
    "\n",
    "print(\"Organizing segments into reaches.\")\n",
    "\n",
    "# reverse the network - track upstream connections\n",
    "rconn = nhd_network.reverse_network(connections)\n",
    "\n",
    "# isolate independent subnetworks\n",
    "subnets = nhd_network.reachable_network(rconn)\n",
    "\n",
    "# identify the segments in each subnetwork\n",
    "subreachable = nhd_network.reachable(rconn)\n",
    "\n",
    "# break each subnetwork into reaches \n",
    "subreaches = {}\n",
    "for tw, net in subnets.items():\n",
    "    path_func = partial(nhd_network.split_at_junction, net)\n",
    "    subreaches[tw] = nhd_network.dfs_decomposition(net, path_func)  \n",
    "\n",
    "print(\"Reach creation complete.\")    \n",
    "\n",
    "#  ------- STEP 3 ---------  \n",
    "\n",
    "print(\"Running network routing computations\")\n",
    "\n",
    "# create a new DataFrame column containing the simulation timestep. \n",
    "data['dt'] = dt\n",
    "\n",
    "# re-name DataFrame columns with specific headers. Needed b/c we reference the DataFrame by these column names exactly.\n",
    "# 0: bw, 1: tw, 2: twcc, 3: dx, 4: n_manning 5: n_manning_cc, 6: cs, 7: s0, 8: qlat\n",
    "column_rename = {\n",
    "    network_data['length_col']: 'dx',\n",
    "    network_data['topwidth_col']: 'tw',\n",
    "    network_data['topwidthcc_col']: 'twcc',\n",
    "    network_data['bottomwidth_col']: 'bw',\n",
    "    network_data['manningncc_col']: 'ncc',\n",
    "    network_data['slope_col']: 's0',\n",
    "    network_data['ChSlp_col']: 'cs',\n",
    "    network_data['manningn_col']: 'n'\n",
    "}\n",
    "data = data.rename(columns=column_rename)\n",
    "\n",
    "# force variable type as float32. Needed b/c of FORTRAN interaction\n",
    "data = data.astype('float32')\n",
    "\n",
    "# loop through each subnetwork and execute the MC routing model\n",
    "results = []\n",
    "for twi, (tw, reach) in enumerate(subreaches.items(), 1):\n",
    "\n",
    "    print(\n",
    "                f\"Now working on: {tw} ...\",\n",
    "                end = \"\", \n",
    "            )\n",
    "\n",
    "    # get a list of segments in the subnetwork\n",
    "    r = list(chain.from_iterable(reach))\n",
    "\n",
    "    # prep parameter and lateral inflow data to be fed to routing model\n",
    "    data_sub = data.loc[r, ['dt', 'bw', 'tw', 'twcc', 'dx', 'n', 'ncc', 'cs', 's0']].sort_index()\n",
    "    qlat_sub = qlats.loc[r].sort_index()\n",
    "\n",
    "    # compute the network routing, append results (flow, depth, and velocity)\n",
    "    results.append(mc_reach.compute_network(\n",
    "        nts, reach, subnets[tw], data_sub.index.values, data_sub.columns.values, data_sub.values, qlat_sub.values\n",
    "        )\n",
    "    )\n",
    "\n",
    "# create a multi-index DataFrame with flow, depth, and velocity simulations\n",
    "fdv_columns = pd.MultiIndex.from_product([range(nts), ['q', 'v', 'd']])\n",
    "flowveldepth = pd.concat([pd.DataFrame(d, index=i, columns=fdv_columns) for i, d in results], copy=False)\n",
    "flowveldepth = flowveldepth.sort_index()\n",
    "\n",
    "print(\"Netowrk routing computations complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the flow output data for a particular subnetwork\n",
    "tailwater_id = 22811611   \n",
    "network_segs = subreachable[tailwater_id]\n",
    "\n",
    "# grab simulated flows for all segments in the network\n",
    "# [i, j, k]:\n",
    "# i = index values for each segment\n",
    "# j = all times\n",
    "# k = the parameter of interest\n",
    "network_flows = flowveldepth.loc[flowveldepth.index.isin(network_segs), (slice(None), 'q')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a GeoDataFrame of points for each link in the stream network\n",
    "dat_geo = nhd_io.read(network_data[\"geo_file_path\"])\n",
    "dat_geo = dat_geo.set_index(network_data[\"key_col\"])\n",
    "\n",
    "if \"mask_file_path\" in network_data:\n",
    "        data_mask = nhd_io.read_mask(\n",
    "            network_data[\"mask_file_path\"],\n",
    "            layer_string=network_data[\"mask_layer_string\"],\n",
    "        )\n",
    "        dat_geo = dat_geo.filter(data_mask.iloc[:, network_data[\"mask_key\"]], axis=0)\n",
    "\n",
    "# create a GeoData Frame        \n",
    "gdf = geopandas.GeoDataFrame(dat_geo, geometry=geopandas.points_from_xy(dat_geo.lon, dat_geo.lat))\n",
    "\n",
    "# clip the GeoDataFrame to include ONLY segments in the specified river network\n",
    "network_gdf = gdf.loc[gdf.index.isin(network_segs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gif\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# network geodata framee\n",
    "network_gdf = gdf.loc[gdf.index.isin(network_segs)]\n",
    "\n",
    "@gif.frame\n",
    "def plot(tstep):\n",
    "    \n",
    "    first_flow = network_flows.loc[:, ((tstep), 'q')]\n",
    " \n",
    "    joined_gdf = network_gdf.join(first_flow)\n",
    "    joined_gdf = joined_gdf.rename(columns = {joined_gdf.columns[-1] : 'flow'})\n",
    "    \n",
    "    # create a figure showing spatial variations in simulated flow and the lateral flow loading\n",
    "    fig = plt.figure(constrained_layout=True)\n",
    "    gs = fig.add_gridspec(4, 3)\n",
    "    ax1 = fig.add_subplot(gs[0:2, :]) # we will make a map on ax1\n",
    "    ax2 = fig.add_subplot(gs[2:3,:])  # we will make a line plot on ax2\n",
    "\n",
    "    # need to adjust the size and position of the map colorbar\n",
    "    divider = make_axes_locatable(ax1)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "    # plot the spatial variation in simulated flow rate, across all stream segments in the network\n",
    "    joined_gdf.plot(markersize = 5, \n",
    "                    column = \"flow\", \n",
    "                    cmap = 'PuBu', \n",
    "                    legend = True, \n",
    "                    vmin = 0, \n",
    "                    vmax = 20000,\n",
    "                    ax = ax1, \n",
    "                    cax = cax, \n",
    "                    legend_kwds={'label': \"Flow (cms)\",\n",
    "                             'orientation': \"vertical\"})\n",
    "\n",
    "    # map title and axis controls\n",
    "    ax1.set_title(\"Mississippi River Basin\", size = 20)\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # plot the timeseris of lateral inflow loading\n",
    "    qlats.iloc[1][0:tstep].plot(ax = ax2, color = 'r', linewidth = 2) # ! make the 5 = tstep\n",
    "    ax2.set_xlim([0, 8000])\n",
    "    ax2.set_ylim([0, 11])\n",
    "    ax2.set_title(\"Lateral Inflow Loading\", size = 20)\n",
    "    ax2.set_ylabel(\"Lateral Inflow (cms per node)\", size = 14)\n",
    "    ax2.set_xlabel(\"Simulated Timestep\", size = 14)\n",
    "\n",
    "    # adjsut the figure size\n",
    "    fig.set_size_inches(10, 10)\n",
    "\n",
    "frames = []\n",
    "for i in range(0,8000,100):\n",
    "    \n",
    "    frame = plot(i)\n",
    "    \n",
    "    frames.append(frame)\n",
    "\n",
    "gif.save(frames, \"../doc/mississippi.gif\", duration = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
